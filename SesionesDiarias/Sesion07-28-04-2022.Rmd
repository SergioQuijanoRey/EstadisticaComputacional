---
title: Sesión de prácticas 7, Estadística Computacional
author:
  - Sergio Quijano Rey
  - sergioquijano@correo.ugr.es
date: 28.04.2022
output:
    html_document:
        toc: true
        toc_depth: 3
        toc_float: false
        collapsed: true
        number_sections: true
---

# Ejercicio 1

## Carga de los datos

Comenzamos cargando los datos con los que vamos a trabajar:

```{r}
employees <- read.table("Employee.txt", header = TRUE, sep = " ", as.is = NA)
```

Mostramos la estructura de los datos cargados:

```{r}
str(employees)
```

Ahora pondremos nombre a los factores, usando la instrucción `within`:

```{r}
employees <- within(employees, {
    gender <- factor(gender, labels = c("female", "male"))
})
str(employees)
```

Simplicamos el código haciendo un `attach` del *dataframe*. Con esto, podemos usar `gender` en vez de `employees$gender`:

```{r}
attach(employees)
```

## Variables cuantitativas. Resúmenes y gráficos

Podemos identificar como variables cuantitativas: `salary`, `startsal`, `age`, `jobtime`, `prevexp` y `edu`. Por su naturaleza podríamos considerar las dos primeras como continuas y resto como discretas. Aunque tenemos que tener en cuenta que todas las variables se han medido de forma discreta. Esto es relevante a la hora de analizar los datos.

Empezamos mostrando un histograma básico del salario (que es una variable continua):

```{r}
hist(salary)
```

Mostramos los metadatos del histograma:

```{r}
res <- hist(salary, plot = FALSE)
res
```

Vemos que por defecto, tenemos pocos intervalos para la naturaleza continua de nuestros datos. Es por ello que ahora hacemos un histograma más avanzado. Para ello, usamos el parámetro `breaks`, especificasndo el número de intervalos que queremos mostrar:

```{r}
hist(salary, breaks = 100)
```

También podemos hacer el histograma definiendo, en `breaks`, los puntos de corte con distinta amplitud, usando una lista:

```{r}
x1 <- seq(15000, 40000, by = 5000)
x2 <- seq(50000, 80000, by = 10000)
x3 <- seq(100000, 140000, by = 20000)
hist(salary, breaks = c(x1, x2, x3))
```

Observar que cuando hacemos un gráfico de barras, con distintas amplitudes en las barras, obtenemos como altura de las barras la densidad de frecuencia (frecuencia dividida por la amplitud).

Un histograma nos da una representación de la distribución de frecuencias y consiste además en un estimador (no paramétrico) de la función de densidad de la variable. Una versión suavizada de este estimador se puede obtener usando la función `density`, que podemos superponer al histograma usando la función `lines`:

```{r}
hist(salary,breaks=c(x1,x2,x3))
lines(density(salary),col='blue')
```

Sobre el gráfico anterior dibujo la función de densidad de una normal, cuya media y desviación típica sean la de los datos de `salary`.

```{r}
# Histograma basico de los datos
hist(salary, breaks = c(x1, x2, x3))

# Funcion de densidad de los datos en azul
lines(density(salary),col='blue')

# Distribucion normal con media y desviacion la de los datos, en rojo sobre el grafico anterior
curve(dnorm(x,mean=mean(salary),sd=sd(salary)),add=TRUE,col='red',lty=2)

# Leyenda explicativa
legend('topright',c('Función de densidad suavizada','Función de densidad Normal'))
```

No parece que sea un buen modelo de probabilidad para los datos, no se ajusta a la distribución que visualizamos con el histograma.

Podemos comprobar esto mismo con un gráfico más adecuado, el **gráfico probabilístico normal**, que es un caso particular de los gráficos **cuantil-cuantil**. Mostramos el gráfico probabilístico normal, en el que mostramos los cuantiles de nuestra distribución frente a los cuantiles de una distribución normal:

```{r}
qqnorm(salary)
```

Aquí vemos con claridad que no tenemos una línea recta, que es lo que se espera si los datos se distribuyen por una distribución normal. Esto se debe a que la cola izquierda de la distribución es mucho más corta que la cola derecha, que sí se parece más a la cola de una normal.

Para confirmar esto, plantearemos un test de hipótesis:

- $H_0$: la variable salario sigue una distribució normal
- $H_1$: la variable salario sigue otra distribución, no normal

Para plantear el contraste usaremos el test *"kolmogorov-Smirnov"* y *"Shapiro-Wilks"*. Empezamos con el test de kolmogorov-Smirnov:

```{r}
ks.test(salary,pnorm,mean=mean(salary),sd=sd(salary))
```

Ahora, vamos con el de Shapiro-Wils:

```{r}
shapiro.test(salary)
```

De estos dos tests, podemos **concluir** que, como el $p-value$ es muy pequeño, rechazamos $H_0$, luego los datos no siguen una distribución de probabilidad normal.

Notar que el primer test nos muestra un *warning*: hay *ties* (valores repetidos) en los datos de `salary`. Esto no tiene sentido al ser una variable continua, pero hay que recordar la discretización que hemos realizado.

Ahora, hacemos un gráfico *boxplot* de la variable `salary`. Son unos gráficos muy útiles para explorar las distribuciones de probabilidad de variables continuas.

```{r}
boxplot(salary)
```

Vemos con este gráfico que los datos pueden tener muchos *outliers* en la cola derecha de la distribución. Acompañamos este gráfico con el `sumary` de la variable, para localizar la mediana y cuartiles:

```{r}
summary(salary)
```

Realizamos ahora un gráfico combinado, mostrando el histograma junto al gráfico de bigotes. Con esto dejamos claro que la variable no sigue una distribución normal:

```{r}
hist(salary,probability=TRUE,main="",axes=FALSE)
axis(1)
lines(density(salary),col='red',lwd=2)
par(new=TRUE) ## Para que el próximo gráfico se superponga al anterior
boxplot(salary,horizontal=TRUE, axes=FALSE,lwd=2)
```

Ahora, usaremos un gráfico de cajas para comparar los salarios según la división que introducen otras variables, como el género, la minoría o la categoría de trabajo:

```{r}
boxplot(salary~gender)
boxplot(salary~minority)
boxplot(salary~jobcat)

# A continuación salario con una doble clasificación
boxplot(salary~gender*jobcat)
```

Algunas conclusiones:

- El salario de las mujeres es mucho menor que el de los hombres
- El salario de las minorías es algo menor que el de las no minorías
- Las diferencias de salario entre mujeres y hombres se mantiene si nos fijamos en los puestos de trabajo

Repetimos el análisis para la variable `startsal`:

```{r}
boxplot(startsal~gender)
boxplot(startsal~minority)
boxplot(startsal~jobcat)
boxplot(startsal~gender*jobcat)
```

Algunas conclusiones

- Los hombres comienzan con un salario mayor que las mujeres
- Personas que no pertenecen a una minoria comienzan con un salario mayor que aquellas personas que si pertenecen
- Manager es el puesto con mayor salario inicial, seguido por guarda de seguridad, y en ultimo lugar 'clerical'
- Sigue siendo clara la brecha salarial por genero cuando separamos por genero y puesto de trabajo
- Ademas, vemos que no hay mujeres en el puesto 'custodial'

Repetimos el análisis para la variable `age`:

```{r}
boxplot(age~gender)
boxplot(age~minority)
boxplot(age~jobcat)
boxplot(age~gender*jobcat)
```

Algunas conclusiones

- La mediana de edad de las mujeres es menor que la de los hombres, pero las mujeres presentan una mayor variedad en la edad
- Las personas que no pertenecen a una minoria presentan una mediana de edad mucho mas bajas que las que si pertenecen
- Ademas, la distribucion de las personas que pertenecen a una minoria es mucho mas simetrica
- Las personas 'custodial' son mayores que los otros dos puestos de trabajo
- Las mujeres manager son mas jovenes que los hombres manager, y con menos rango en la edad
- Las mujeres 'clerical' tienen una mediana de edad parecida a los hombres 'clerical', pero presentan muchisima mas variedad en la edad

# Análisis conjunto de dos variables

## Análisis conjunto de dos variables: `salary` y `startsal`

Vamos a analizar las posibles relaciones entre el salario actual y el salario inicial. Hacemos esto con un gráfico de dispersión para estas dos variables:

```{r}
plot(startsal,salary)
```

Con este gráfico, podemos pensar que existe una fuerte relación lineal entre las dos variables. Por eso, plantearemos un modelo de regresión lineal del tipo $salary = \beta_0 + \beta_1 \cdot startsal + \epsilon$. Comenzamos realizando el ajuste y mostrando los resultados:

```{r}
mod <- lm(salary~startsal)
mod
```

Mostramos ahora gráficamente el resultado de la regresión:

```{r}
plot(startsal, salary)
abline(mod, col = "blue")
```

Veo ahora, con `summary`, la calidad de la regresión realizada:

```{r}
summary(mod)
```

Con un $R^-2$ ajustado de $0.7744$, podemos pensar que la relación lineal es lo suficientemente fuerte como para considerarse.

## Análisis conjunto de dos variables: `salary` y `age`

De nuevo, realizamos el ajuste y mostramos los resultados:

```{r}
mod<-lm(salary~age)
mod
```

Mostramos gráficamente el ajuste realizado:

```{r}
plot(age, salary)
abline(mod, col = 'blue')
```

Veamos la calidad del ajuste realizado:

```{r}
summary(mod)
```

**Conclusiones**:

- Cada año que pasa parece que se pierden ~200$
- Sin embargo, no parece que haya mucha correlacion (por lo que muestra el grafico)
- De hecho, el valor de $R^2$ es muy pequeño, por lo que no podemos considerar la relación lineal

## Análisis conjunto de dos variables: `salary` y `education`

Empezamos realizando el ajuste y mostrando el resultado:

```{r}
mod <- lm(salary~edu)
mod
```

Ahora mostramos gráficamente el ajuste realizado:

```{r}
plot(edu, salary)
abline(mod, col = 'blue')
```

Y veamos la calidad del ajuste realizado:

```{r}
summary(mod)
```

**Conclusiones**:

- Conforme aumenta el valor de la educacion, aumenta el salario notablemente
- Esto tiene logica si en los datos un mayor valor del factor 'edu' corresponde a una educacion mayor
- El valor de $R^2$ no es muy alto, pero tampoco es muy bajo. Por tanto, aunque no podamos usar esta regresión con fines predictivos, sí que nos sirve para relacionar las variables como lo hemos hecho previamente (mayor educación $\Rightarrow$ mayor salario)


# Variables cualitativas: tablas de frecuencias y gráficos

Las variables cualitativas, en formato factor, de nuestro dataset, son:

- `gender`
- `jobcat`
- `minority`

## Estudio de `jobcat`

Podemos construir tablas de frecuencias (absolutas con `table` o relativas con `prop.table`) unidimensionales. Mostramos estas tablas para `jobcat`.

Frecuencias absolutas:

```{r}
tab <- table(jobcat)
tab
```

Frecuencias relativas:

```{r}
tab.fi <- prop.table(tab)
tab.fi
```

También podemos construir una tabla clásica de frecuencias:

```{r}
data.frame(tab, Freq.rel = as.numeric(tab.fi))
```

Podemos hacer gráficos de barras y de sectores. Por ejemplo para la variable `jobcat`, empezando por el gráfico de barras:

```{r}
barplot(tab)
```

Y ahora con el gráfico de sectores:

```{r}
pie(tab)
```

## Estudio de `gender`

Repetimos el análisis para la variable `gender`, empezando por la tabla cásica de frecuencias:

```{r}
tab <- table(gender)
tab.fi <- prop.table(tab)
data.frame(tab, Freq.rel = as.numeric(tab.fi))
```

Vemos que tenemos menos mujeres (41 menos) que hombres. Pasamos a mostrar los gráficos de barras y de sectores:


```{r}
barplot(tab)
pie(tab)
```

Con estos dos gráficos vemos lo que ya habíamos comentado previamente.

## Estudio de `minority`

Repetimos el análisis para la variable `minority`, empezando por la tabla cásica de frecuencias:

```{r}
tab <- table(minority)
tab.fi <- prop.table(tab)
data.frame(tab, Freq.rel = as.numeric(tab.fi))
```

Del mismo modo, tenemos 265 personas menos de una minoria que de una no minoría. Esto se va a hacer explícito en los siguientes dos gráficos:

```{r}
barplot(tab)
pie(tab)
```

## Análisis conjunto de `jobcat` y `gender`

Mostramos la tabla de contingencia (frecuencias) de las dos variables `jobcat` y `gender`, conjuntamente.

```{r}
tab2 <- table(jobcat, gender)
tab2
```

Podemos añadir las sumas por filas y columnas:

```{r}
addmargins(tab2)
```

Podemos visualizar estas tablas de contingencia, con **gráficos de barras agrupadas o apiladas**:

```{r}
barplot(tab2)
```

Notar que:

- Tenemos dos valores, uno por cada valor del factor del género
- Tenemos tres barras apiladas, una por cada valor de `jobcat`

Por tanto, parece necesario indicar esta información en el gráfico anterior:

```{r}
barplot(
    tab2,
    legend.text = TRUE,
    args.legend = list(x = 'topleft', bty = 'n'),
    ylim = c(0, 300),
    density = 30, col=c('green', 'blue', 'red'),
    main = 'Number of employees by gender and job category'
)

barplot(
    tab2,
    legend.text = TRUE,
    args.legend = list(x='top',  bty='n'),
    density = 30,
    col = c('green', 'blue','red'),
    main = 'Number of employees by gender and job category',
    beside = TRUE
)
```

## Análisis conjunto de `jobcat` y `minority`

Empezamos mostrando la tabla de contingencia, en la que ya añadimos la suma de las variables por separado:


```{r}
tab2 <- table(jobcat, minority)
addmargins(tab2)
```

Mostramos ahora el gráfico de barras apiladas:


```{r}
barplot(
    tab2,
    legend.text = TRUE,
    args.legend = list(x = 'topleft', bty = 'n'),
    ylim = c(0, 300),
    density = 30, col=c('green', 'blue', 'red'),
    main = 'Number of employees by minority and job category'
)

barplot(
    tab2,
    legend.text = TRUE,
    args.legend = list(x='top',  bty='n'),
    density = 30,
    col = c('green', 'blue','red'),
    main = 'Number of employees by minority and job category',
    beside = TRUE
)
```

De la tabla de contingencias y de las dos gráficas sacamos las siguientes **conclusiones**:

- El procentaje de puestos de trabajo de más alta categoría (*custodial*, *manager*) es mucho menor en minorías que en no minorías
- El porcentaje de *managers* es mucho más elevado en no minorias
- Por tanto, es muchísimo más difícil escalar de puesto de trabajo si pertecenes a una minoría que si no perteneces

# Ejercicio Propuesto

Vamos a trabajar con el *dataset* `airquality`, que procedo a cargar:

```{r}
dataset <- airquality
head(dataset, 5)
```

Voy a darle nombre a los meses, porque en un gráfico posterior me será útil

```{r}
dataset <- within(dataset, {
    # Uso month.name para obtener los meses del año
    # Solo hay meses del 5 al 9, asi que solo me quedo con esos nombres
    Month <- factor(Month, labels = month.name[5:9])
})
```

## Primer ejercicio

**Enunciado**: Construir un histograma del contaminante Ozone considerando intervalos de amplitud 10.

```{r}
# Maximo y minimo para calcular el numero de breaks que tenemos que hacer
min.ozone <- min(dataset$Ozone, na.rm = TRUE)
max.ozone <- max(dataset$Ozone, na.rm = TRUE)

# Histograma
hist(
    dataset$Ozone[is.na(dataset$Ozone) == FALSE],
    breaks = (max.ozone - min.ozone) / 10.0,
    main = "Histograma del ozono",
    xlab = "Valor del ozono"
)
```

## Segundo ejercicio

**Enunciado**: Superponer al histograma anterior la función de densidad de una distribución normal cuyos parámetros media y desviación típica sean las de los datos Ozone. ¿Te parece que estos datos se podrían modelizar mediante ese modelo de probabilidad?

```{r}
# Volvemos a poner el histograma del ejercicio anterior
ozone.min <- min(dataset$Ozone, na.rm = TRUE)
ozone.max <- max(dataset$Ozone, na.rm = TRUE)
hist(
    dataset$Ozone[is.na(dataset$Ozone) == FALSE],
    breaks = (ozone.max - ozone.min) / 10.0,
    main = "Histograma del ozono",
    xlab = "Valor del ozono"
)

# Añadimos la distribucion normal
ozone.mean <- mean(dataset$Ozone, na.rm = TRUE)
ozone.sd <- sd(dataset$Ozone, na.rm = TRUE)
curve(pnorm(x, mean = ozone.mean, sd = ozone.sd), col = "blue", add = TRUE)
```

A simple vista es muy fácil comprobar que una distribución normal no parece ser una buena distribución para modelar los datos.

## Tercer ejercicio

**Enunciado**: Construir un gráfico de normalidad para la variable Ozone. ¿Qué te indica el gráfico? Confirmar el resultado con un contraste de hipótesis.

Empezamos mostrando el gráfico de normalidad:

```{r}
qqnorm(salary)
```

Vemos que la distribución de los datos no sigue una normal, pues el gráfico de normalidad no se asemeja a una línea recta. El gráfico nos muestra que la cola derecha es mucho más ligera y parecida a una normal que la cola izquierda. Confirmamos esto con un contraste de hipótesis:

```{r}
ks.test(salary,pnorm,mean=mean(salary),sd=sd(salary))
```

Podemos **concluir** que, como el $p-value$ es muy pequeño, rechazamos $H_0$, luego los datos no siguen una distribución de probabilidad normal.

## Cuarto ejercicio

**Enunciado**: Construir un diagrama de cajas del contaminante Ozone. ¿Qué puedes interpretar del gráfico?

```{r}
boxplot(dataset$Ozone)
```

- Podemos ver que tenemos dos *outliers*, con valores de concentración de ozono demasiado altos.
- También podemos ver que la distribución de los datos está más concentrada en valores bajos, que en valores altos
- La cola de la izquierda es más pesada que la cola de la derecha

## Quinto ejercicio

**Enunciado**: Construir un diagrama de cajas múltiple del contaminante Ozone que permita comparar sus valores en los meses de mayo, junio, julio, agosto y septiembre. ¿Qué puedes interpretar del gráfico?

```{r}
boxplot(dataset$Ozone ~ dataset$Month, xlab = "Mes", ylab = "Concentración de Ozono")
```

Lo que parece claro con este gráfico es que en los messe de verano, aumenta la concentración de Ozono. Podemos suponer que esto se debe a una temperatura más alta, menos precipitaciones, ...

## Sexto ejercicio

**Enunciado**: Construir dos diagramas de dispersión que nos permita visualizar la posible relación entre: (i) la velocidad del viento, Wind, y el contaminante Ozone; y (ii) la temperatura, Temp, y Ozone. ¿Qué puedes interpretar de los gráficos?

Empiezo mostrando el diagrama de dispersión de las variables `Wind, Ozone`:

```{r}
plot(dataset$Wind, dataset$Ozone, xlab = "Velocidad del viento", ylab = "Concentración de Ozono")
```

A partir de este gráfico:

- Parece que a mayor velocidad del viento, menor concentración de Ozono en el aire. Esto se corresponde con nuestro sentido común

Ahora muestro el diagrama de dispersión de las variables `Temp, Ozone`:

```{r}
plot(dataset$Temp, dataset$Ozone, xlab = "Temperatura", ylab = "Concentración de Ozono")
```

A partir de este gráfico:

- Parece confirmarse lo que ya habíamos comentado al observar los meses. A mayor temperatura, mayor concentración de Ozono en el aire

En ambos casos, esto que hemos comentado podemos intentar cuantificarlo realizando una regresión lineal, y viendo la relación que conseguimos así y la calidad de dicho ajuste.
