---
title: Sesión de prácticas 10, Estadística Computacional
author:
  - Sergio Quijano Rey
  - sergioquijano@correo.ugr.es
date: 19.05.2022
output:
    html_document:
        toc: true
        toc_depth: 3
        toc_float: true
        collapsed: true
        number_sections: true
---

# Tarea 1. Aproximación de una probabilidad

Partimos de $X, Y \sim \mathcal{U}[-1, 1]^2$ y queremos calcular mediante una simulación la probabilidad $P(X + Y \leq 0)$.

```{r}
# Lanzamos 1000 simulaciones
nsim<-1000
set.seed(1)
x<-runif(nsim,-1,1)
y<-runif(nsim,-1,1)

# Calculamos la aproximacion
suceso<-(x+y<=0)
mean(suceso)
```

Además, calcularemos el error y mostraremos el gráfico de convergencia:

```{r}
# Error de estimación
sd(suceso)/sqrt(nsim)
```

```{r}
estim<-cumsum(suceso)/(1:nsim)

# errores de estimación correspondientes
estim.err<-sqrt(cumsum((suceso-estim)^2))/(1:nsim)
plot(
    1:nsim,
    estim,
    type='l',
    ylab='Aproximación y límites de error',
    xlab='Número de simulaciones',
    main=expression(P(X+Y<=0)),
    ylim=c(0,1)
)
z<-qnorm(0.025,lower.tail = FALSE)
lines(estim - z*estim.err,col='blue',lwd=2,lty=3)
lines(estim + z*estim.err,col='blue',lwd=2,lty=3)
```

Podemos comparar con el valor exacto, que en este caso es $\frac{1}{2}$:

```{r}
exact_value <- 1/2
abs_diff <- abs(exact_value - mean(suceso))
abs_diff

rel_diff <- abs_diff / exact_value * 100
rel_diff
```

Repetimos el mismo experimento para $P(X^2 + Y^2 \leq 1)$, cuyo valor verdadero sabemos que es $\frac{\pi}{4}$. Empezamos de nuevo calculando la estimación:

```{r}

# Lanzamos 1000 simulaciones
nsim <- 1000
set.seed(1)
x <- runif(nsim,-1,1)
y <- runif(nsim,-1,1)

# Calculamos la aproximacion
suceso <- (x^2+ y^2 <= 1)
approx_value <- mean(suceso)
approx_value
```

Vemos el error cometido:

```{r}
# Error de estimación
sd(suceso)/sqrt(nsim)
```

Y el gráfico de convergencia:

```{r}
estim<-cumsum(suceso)/(1:nsim)

# errores de estimación correspondientes
estim.err<-sqrt(cumsum((suceso-estim)^2))/(1:nsim)
plot(
    1:nsim,
    estim,
    type='l',
    ylab='Aproximación y límites de error',
    xlab='Número de simulaciones',
    main=expression(P(X^2+Y^2<=1)),
    ylim=c(0,1)
)
z<-qnorm(0.025,lower.tail = FALSE)
lines(estim - z*estim.err,col='blue',lwd=2,lty=3)
lines(estim + z*estim.err,col='blue',lwd=2,lty=3)
```

Comparamos con el valor real de la probabilidad:

```{r}
exact_value <- pi / 4.0
abs_diff <- abs(exact_value - approx_value)
abs_diff

rel_diff <- abs_diff / exact_value * 100
rel_diff
```

Con esto podemos ver que ambas simulaciones de la probabilidad nos dan resultados satisfactorios.

# Tarea 2. Aproximación de una integral

Partimos de la función $f(x)$ función de densidad de una distribución Beta con parámetros $a = 2.5, b = 5$ y las dos integrales que se indican en el enunciado.

## Gráficos de las funciones a integrar

Mostramos en los siguientes gráficos las dos funciones que vamos a integrar:

```{r}
# primera integral
f1<-function(x) dbeta(x,2.5,5)
curve(f1(x),0.2,0.4)

# segunda integral
f2<-function(x) sin(x)*exp(-x)*dbeta(x,2.5,5)
curve(f2(x),0,1)
```

## Cálculo aproximado mediante simulaciones de la integral

Ahora realizamos la aproximación de la integral usando simulaciones.

### Primera integral

Para la primera integral usamos **integración Monte Carlo clásica**, en un intervalo que no sea $(0, 1)$:

```{r}
# Establecemos las condiciones de la simulacion
set.seed(1)
nsim <- 1000

# Limites de la integral
lower <- 0.2
upper <- 0.4

# Funcion que vamos a integrar
f <- function(x) dbeta(x, 2.5, 5)

# Muestreo de una uniforme U(a, b)
x_values <- runif(nsim, lower, upper)

# Ahora calculo la aproximacion de la integral
approx_int <- (upper - lower) / nsim * sum(f(x_values))
approx_int
```

Veamos ahora el gráfico de convergencia, usando ahora una funcion que sirve para esta y otras integrales parecidas:

```{r}
# Integral de montecarlo para una funcion `f` en un intervalo (`lower`, `upper`)
# Se usan `nsim` simulaciones para aproximar la integral
# Se muestra el grafico de convergencia cuando `should_plot == TRUE`
montecarlo_acotado <- function(f, nsim = 1000, lower = 0, upper = 1, should_plot = FALSE){

    # Realizamos el muestreo de valores y mapeo por la funcion
    x_values <- runif(nsim, lower, upper)
    fx <- sapply(x_values, f)

    # Aproximaciones para $n=1,...,nsim$
    estim <- ((upper - lower) / (1:nsim)) * cumsum(fx)

    # errores de estimación correspondientes
    estim.err <- sqrt(cumsum((fx-estim)^2))/(1:nsim)
    if(should_plot == TRUE) {
        plot(1:nsim,estim,type='l',ylab='Aproximación y límites de error',xlab='Número de simulaciones')
        z<-qnorm(0.025,lower.tail = FALSE)
        lines(estim - z*estim.err,col='blue',lwd=2,lty=3)
        lines(estim + z*estim.err,col='blue',lwd=2,lty=3)
        abline(h = approx_int,col=2)
    }

    # Aproximación final y su error
    estim[nsim]
    estim.err[nsim]

    # Devolvemos los datos
    return(list(aproximacion = estim[nsim], error = estim.err[nsim], secuencia = estim))
}


# Condiciones de la simulacion
nsim <- 1000
set.seed(1)

montecarlo_acotado(f, nsim = nsim, lower = lower, upper = upper, should_plot = TRUE)
```

### Segunda Integral

Para la segunda integral tenemos que usar **integral con límites infinitos**. Para ello, tenemos que descomponer la función de la integral en el producto de una función que multiplica a una función que sea función de densidad. En nuestro caso es claro que tenemos que hacer:

- $f(x) = dbeta(x, 2.5, 5)$
- $c(x) = sin(x) e^{-x}$

```{r}
# Establecemos las condiciones de la simulacion
set.seed(1)
nsim <- 1000

# Descomposicion de las funciones
# La funcion f no la ponemos, porque es de la que vamos a muestrear
c <- function(x) sin(x) * exp(-x)

# Muestreo aleatorio desde la distribucion dada por f
x_values <- rbeta(nsim, 2.5, 5)

# Aproximamos la integral, primero mapeando y luego ponderando
c_values <- c(x_values)
second_approx_int <- sum(c_values) / nsim
second_approx_int
```

Ahora calculamos el error de la aproximación y mostramos el gráfico de convergencia, usando para ello una funcion adecuada y reutilizable

```{r}
# Condiciones de la simulacion
nsim <- 1000
set.seed(1)

# Descomposicion de las funciones
# La funcion f no la ponemos, porque es de la que vamos a muestrear
c <- function(x) sin(x) * exp(-x)

# Funcion para muestrear de la distribucion
# A dicha funcion se le pasa el numero de simulaciones que queremos tomar
# Nos apoyamos en la funcion `rbeta` de distribucion para generar la funcion
g <- function(n) rbeta(nsim, 2.5, 5)

# Integración de montecarlo en limites infinitos
# Se debe haber descompuesto la funcion a integrar convenientemente
# `g` debe ser una funcion `g(numero_simulaciones)` que de la distribucion de probabilidad
# `c` debe ser la funcion de ponderado
# Se muestra el grafico de convergencia cuando `should_plot == TRUE`
montecarlo_infinito <- function(g, c, should_plot = FALSE) {


    # Realizamos el muestreo de valores y mapeo por la funcion
    x_values <- g(nsim)
    fx <- sapply(x_values, c)

    # Aproximaciones para $n=1,...,nsim$
    estim <-  cumsum(fx) / (1:nsim)

    # errores de estimación correspondientes
    estim.err <- sqrt(cumsum((fx-estim)^2))/(1:nsim)

    # Mostramos la funcion cuando asi se indique
    if(should_plot == TRUE) {
        plot(1:nsim,estim,type='l',ylab='Aproximación y límites de error',xlab='Número de simulaciones')
        z<-qnorm(0.025,lower.tail = FALSE)
        lines(estim - z*estim.err,col='blue',lwd=2,lty=3)
        lines(estim + z*estim.err,col='blue',lwd=2,lty=3)
        abline(h = second_approx_int,col=2)
    }

    # Devolvemos los datos
    return(list(aproximacion = estim[nsim], error = estim.err[nsim], secuencia = estim))
}

montecarlo_infinito(g, c, should_plot = TRUE)
```

## Comparación con los valores verdaderos de la integral

Aparentemente ambas aproximaciones han sido buenas. Veamos ahora si esto es verdad comparando con los verdaderos valores de la integral.

### Comparación con la primera integral

Calculamos el verdadero valor de la primera integral:

```{r}
f1 <- function(x) dbeta(x,2.5,5)
real_int <- integrate(f1,0.2,0.4)
real_int
```

Comparamos con nuestra aproximación:

```{r}
abs_err <- abs(real_int$value - approx_int)
abs_err

rel_err <- abs_err / real_int$value * 100
rel_err
```

Podemos ver que, en el caso de la primera aproximación, el resultado es satisfactorio. Además, obtenemos un error menor que la estimación del error realizada en apartados anteriores.

### Comparación con la segunda integral

Calculamos el verdadero valor de la segunda integral:

```{r}
f2 <- function(x) sin(x) * exp(-x) * dbeta(x, 2.5, 5)
real_int <- integrate(f2, -Inf, Inf)
real_int
```

Comparamos con nuestra aproximación:

```{r}
abs_err <- abs(real_int$value - second_approx_int)
abs_err

rel_err <- abs_err / real_int$value * 100
rel_err
```

De nuevo, vemos que la aproximación es satisfactoria. Además, el error real es menor que el error que hemos estimado en apartados anteriores.

# Tarea 3. Aproximación de una distribución de probabilidad

Buscamos aproximar una distribución de *Poisson* compuesta:

$$S_N = \sum_{i = 1}^N X_i$$

donde $N \sim \mathcal{P}(N)$ y $X_1, \ldots, X_N$ son variables aleatorias *iid*.

Además, tenemos que:

$$\mathbb{E}[S_N] = \mathbb{E}[N] \cdot \mathbb{E}[X_1]$$
$$\mathbb{Var}[S_N] = \mathbb{E}[N] \cdot \mathbb{Var}[X_1] + \mathbb{Var}[N] \cdot \mathbb{E}[X_1]^2$$

En lo que sigue, suponemos que $\lambda = 17$ y que $X_i \sim lognorm(\mu = 3.5, \sigma = 1.1)$.

Con esto, podemos calcular de forma exacta la media y varianza de la distribución compuesta:

```{r}
# Parámetros de la lognormal (X)
mu <- 3.5
sig <- 1.1

# A partir de ellos calculamos E[X] y V(X)
EX<- exp(mu+sig^2/2)
EX
VX<- EX^2*(exp(sig^2)-1)
VX

# Parámetro de la Poisson (N)
lam<- 17 # coincide con E[N] y V(N)

# Media de la Poisson compuesta
ES<-lam*EX
ES

# Varianza de la Poisson compuesta
VS<- lam*VX + lam*EX^2
VS
```

Ahora, buscamos aproximar la distribución de probabilidad tomando $n$ muestras aleatorias de la distribución. La función de densidad se puede aproximar por el histograma que generemos de las $n$ muestras de la distribución:

```{r}
# Numero de simulaciones que vamos a tomar
nsim <- 5000

# Simulamos ahora nsim valores de S_N:
S <- double(nsim) # Para almacenar los valores simulados
set.seed(1)

for (i in 1:nsim) {
    n <- rpois(1, lam)
    if (n > 0) S[i] <- sum(rlnorm(n, mu, sig))
}

# El vector S contiene los valores simulados de S_N
# un histograma de S nos da una aproximación de la distribución
# Cambio el codigo dado en el guion de practicas porque me daba un error
hist(S, breaks = 20, prob = TRUE)

# Podemos superponer la densidad suavizada que calcula density()
lines(density(S), col = "red")
```

Ahora calculo la media y varianza de los valores generados, que nos aproximarán la media y varianza reales:

```{r}
exper_mean <- mean(S)
exper_mean

exper_var <- var(S)
exper_var
```

Veamos **cómo de parecidos** son respecto los valores reales de estas métricas, empezando por la media:

```{r}
abs_err <- abs(ES - exper_mean)
abs_err

rel_err <- abs_err / ES * 100
rel_err
```

Repetimos lo mismo pero para la varianza:

```{r}
abs_err <- abs(VS - exper_var)
abs_err

rel_err <- abs_err / VS * 100
rel_err
```

Por lo tanto:

- La media tiene un error relativo de aproximadamente $0.2\%$, y la varianza de $1.73\%$
- En ambos casos, podemos pensar que hemos obtenido un resultado satisfactorio

Ahora, con las simulaciones de la distribución, podemos calcular el **Value at Risk** como el cuantil 99.5%:

```{r}
value_at_risk <- quantile(S, 0.995)
value_at_risk
```

Comparamos con el **Value at Risk** que nos daría una aproximación normal, usando la media y varianza:

```{r}
# aproximación por una Normal con media ES y varianza VS
qnorm(0.995, mean=ES, sd=sqrt(VS))
```
