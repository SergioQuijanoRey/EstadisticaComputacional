---
title: Sesión de prácticas 9, Estadística Computacional
author:
  - Sergio Quijano Rey
  - sergioquijano@correo.ugr.es
date: 12.05.2022
output:
    html_document:
        toc: true
        toc_depth: 3
        toc_float: true
        collapsed: true
        number_sections: true
---

# Notas previas

- Algunas salidas se muestran mal porque uso mucho `message` y `print`
- Antes usaba estas funciones para mostrar por la consola de *Linux* los resultados y distintas secciones de la práctica
- Para mejorar las salidas del programa, muchos `message()` se pueden sustituir por texto en *markdow* que muestre las mismas indicaciones que estaba mostrando con los mensajes en `R`.
- Hago este proceso a mano, para mejorar la legibilidad del *notebook*

# Carga de los datos

Hacemos `as.is = NA` para que todos los factores se identifiquen en el dataframe como tal

```{r }
hatco <- read.csv("hatco2.csv", header = TRUE, as.is = NA)
```

Las primeras 10 filas del *dataframe* son:

```{r}
head(hatco, 10)
```

La estructura del *dataframe* leído es:

```{r}
str(hatco)
```

Representamos graficamente las variables con las que vamos a estar trabajando Nos interesa ver las correlaciones entre las variables

```{r }
plot(hatco[,c(6:13)])
```

Podemos ver que la fidelidad (variable que queremos predecir en base a las otras) esta ligeramente correlada linealmente con:

- Velocidad
- Servconj
- Flexprec (ligeramente)

Algunas variables explicativas parecen ser algo colineales:

- Imgfvent y Imgfabri
- Servconj y velocidad
- Servconj y precio (muy ligeramente)

# Ajuste de un modelo lineal a los datos

Realizamos el ajuste lineal

```{r }
mod1 <- lm(fidelidad~velocidad+precio+flexprec+imgfabri+servconj+imgfvent+calidadp, hatco)
mod1
```

## Estudio de la bondad del ajuste

Miramos la bondad del ajuste

```{r }
print(summary(mod1))
```

Realizamos el test ANOVA

```{r }
anovares <- anova(mod1)
anovares
```
Usamos summary para ver si las percepciones son relevantes en la variable de salida:
Viendo los p-valores que estan por debajo de 0.05, las unicas variables relevantes son (las que rechazan H0):

<!-- TODO -- Aqui no estoy usando para nada el test ANOVA, creo que solo estoy usando el summary del mod1 -->

- Flexprec
- Servconj
- Y ademas el parametro independiente $\beta_0$

A un nivel de significación del 1%

- Intercept ($\beta_0$) se rechaza pues su p-valor es $0.044 > 0.01$

# Estudio del *dataset*

## Estudiamos la homocedasticidad

```{r }
residuos <- rstandard(mod1)
predicciones <- mod1$fitted.values #' Las predicciones ya nos las da el objeto devuelto por lm
```
Gráfico de dispersión de los pares $\hat{y_i}, r_i$

```{r}
plot(predicciones, residuos)
```

Grafico de dispersion de los pares $x_{ij}, r_i$

```{r, fig.height=20, fig.width=15}
par(mfrow=c(4,2))
for(j in 6:13){
  plot(hatco[, j], residuos)
}
```

**Conclusiones**:

- Todos estos graficos muestran nubes de puntos aleatorias
- Ademas, la dispersion parece uniforme, salvo en valores de la variable x_i donde tenemos pocos puntos

## Estudiamos la incorrelacion

Empezamos realizando una comprobación gráfica de que los datos están incorrelados. Para ello, mostramos gráficamente los errores estandarizados (que anteriormente calculábamos con `rstandar`) frente a la variable `empresa`

```{r}
plot(hatco$empresa, residuos)
```

A partir de estas gráficas, podemos extraer las siguientes **conclusiones**:

- Parece que estamos visualizando un patrón aleatorio en la gráfica
- Por tanto, parece que no existen las correlaciones que podrían invalidar las hipótesis iniciales que hemos tomado como dadas y que ahora estamos comprobando

Ahora, usamos el *test* de *Durbin-Watson* para comprobar lo que hemos comentado previamente:

```{r}
# TODO -- no consigo instalar esta libreria
# library(lmtest)
# dwtest(modelo)
```

## Estudiamos la normalidad de los errores

Los errores del modelo se asumen normales. Dicha hipótesis es fundamental para el desarrollo de la inferencia. Por tanto es esencial verificar esta hipótesis.

Para realizar dicha verificación vamos a usar el *test* *Kolmogorov-Smirnov*:

```{r}
# Tomamos la media y desviacion de los residuos, porque estos parametros son necesarios para la
# funcion ks.test. Si no pasamos estos parametros, se supone media cero y desviacion 1
# Notar que deberian ser media cero y desviacion uno porque son residuos estandarizados. Pero tomamos
# estos valores por si han ocurrido errores numericos, paliarlos un poco
residuos.mean <- mean(residuos)
residuos.sd <- sd(residuos)


# Especificamos "pnorm" porque es la cdf de la distribucion con la que queremos comprobar
ks.test(residuos, "pnorm", residuos.mean, residuos.sd)
```

Vemos que los residuos tienen media cero y desviación 1, porque como decimos en el comentario, estamos usando los residuos estandarizados:

```{r}
residuos.mean
residuos.sd
```

Se confirma lo que decíamos anteriormente.

Respecto a los resultados del *test*, extraemos las siguientes **conclusiones**:

- Tenemos que $p-value \geq 0.05$, luego no podemos rechazar la hipótesis nula
- Dicha hipótesis nula es que la distribución de los datos no sigue una normal estándar
- Por tanto, no tenemos evidencia para pensar que los residuos no sigan una normal estándar, así que podemos pensar que sí que la sigue

Ahora, para reforzar el resultado del test *Kolmogorov-Smirnov*, mostramos una visualización usando un **gráfico probabilístico normal** (también llamado gráfico *cuantil-cuantil*) usando `qqnorm`:

```{r}
qqnorm(residuos)

# Usamos qqline para mostrar la linea que deberia seguir los datos para que al distribucion
# siguiese realmente una distribucion normal
qqline(residuos)
```

Con este gráfico lo que buscamos es que los datos se muestren gráficamente aproximadamente como una línea recta. Por tanto:

- Los residuos se distribuyen de forma parecida a una normal, aunque no se ajusten a esta distribución perfectamente
- Esto, en conjunto con los resultados del *test de Kolmogorov-Smirnov*, podemos pensar que los residuos siguen una distribución normal estándar, como buscábamos


## Estudiamos la linealidad de los errores

Hemos supuesto previamente la linealidad en la relación entre la respuesta y las variables explicativas. Esto se puede comprobar en los gráficos de dispersión que hemos mostrado previamente. Pero para esta tarea son más adecuados los gráficos *componente más residuo*, que mostramos a continuación:

```{r}
# Esta libreria no viene instalada por defecto, asi que hay que instalarla
# antes de usarla antes de usarla
# TODO -- descomentar cuando tenga instalada la libreria
# library(car)
```

## Identificación de datos anómalos

Como datos anómalos identificamos aquellos datos cuyos residuos sean excesivamente grandes. Para ello, consideraremos los residuos estandarizados o estudentizados, y detectaremos datos anómalos aquellos cuyos residuos estén por encima del rango $(-2, 2)$, y excesivamente anómalos aquellos que estén por encima del rango $(-3, 3)$.

A continuación, localizo las empresas con un residuo $|res_i| > 2.5$:

```{r}
# Selecciono aquellas filas que cumplen la condicion buscada
empresas_anomalas <- hatco[abs(residuos) > 2.5, ]$empresa
empresas_anomalas
```

Por tanto, vemos que tenemos dos empresas anómalas, la empresa con identificador 7 y la empresa con identificador 100. Repito lo anterior pero usando como umbral $2$ en vez de $2.5$:

```{r}
# Selecciono aquellas filas que cumplen la condicion buscada
empresas_anomalas <- hatco[abs(residuos) > 2, ]$empresa
empresas_anomalas
```

Con este criterio más suave (es más propenso a detectar anomalías), tenemos también las empresas 11 y 14 como empresas anómalas.

## Identificación de datos influyentes

Como datos influyentes identificamos aquellos que tienen un impacto desproporcionado sobre los resultados de la regresión. Si además se tratan de datos aislados, estos datos deberían ser tratados.

Para identificar estos datos, usaremos la **distancia de Cook** $D_i$ que calcularemos usando `cooks.distance`. Realizamos dicho estudio y mostramos las distancias gráficamente:

```{r}
distancias <- cooks.distance(mod1)
plot(
     hatco$empresa, distancias,
     main = "Distancia Cook de cada una de las empresas",
     ylab = "Distancia Cook",
     xlab = "Identificador de la empresa"
)
```

En esta gráfica vemos que hay datos cuya distancia *Cook* (recordemos que mide la influencia que han tenido los datos en la regresión) es mucho más grande que el resto de datos. Especialmente uno hacia la izquierda (entre el 0 y el 20) y el valor 100. Sabemos que el 100 tiene un residuo demasiado elevado. Veamos si localizamos el otro dato, que sospechamos que es el 7 (por el previo estudio de residuos):

```{r}
empresas_distancias_anomalas <- hatco[distancias > 0.05, ]$empresa
empresas_distancias_anomalas
```

Efectivamente, son las empresas que ya habíamos detectado como anómalas al estudiar sus residuos estandarizados. Por tanto, sabemos que estos datos que han sido demasiasdo influyentes en la regresión son datos anómalos. Esto puede ser negativo porque los valores anómalos pueden estar empeorando los resultados de la regresión.

Todo este trabajo se simplifica bastante con la librería `car`. Mostramos cómo se usa a continuación:

```{r}
# TODO -- descomentar cuando consiga instalar la libreria
# library(car)
# influenceIndexPlot(mod1)
```


## Identificación de datos aislados

Para medir el aislamiento de estos datos usaremos los valores de la diagonal de la matriz *hat*: $\hat{H} = X (X X')^{-1} X'$ que se puede obtener con la función `hatvalues`.

Estudiamos dichos *hatvalues* y los mostramos gráficamente:

```{r}
hatvalues <- hatvalues(mod1)
plot(
    hatco$empresa, hatvalues,
    main = "hatvalues de cada una de las empresas",
    ylab = "hatvalue",
    xlab = "Identificador de la empresa"
)
```

Visualmente, identificamos dos empresas con *hatvalues* desproporcionados. Además, no se pueden tratar de las empresas 7 y 100. Veamos de qué empresas se tratan:

```{r}
empresas_hatvalues_anomalos <- hatco[hatvalues > 0.35, ]$empresa
empresas_hatvalues_anomalos
```

Tenemos por tanto dos empresas que podrían necesitar de un estudio independiente, la 22 y la 55, por estar demasiado aisladas.

Puedo mostrar gráficamente estas empresas que se han detectado como excesivamente aisladas:

```{r}
# Muestro graficamente estas empresas anomalas
plot(
    hatco$empresa, hatvalues,
    main = "hatvalues de cada una de las empresas",
    ylab = "hatvalue",
    xlab = "Identificador de la empresa"
)

# pch = 21 es para que el circulo salga rellenado y no vacio
points(empresas_hatvalues_anomalos, hatvalues[empresas_hatvalues_anomalos], col = "blue", pch = 19)
```

Veamos el residuo que tienen estos valores aislados:

```{r}
residuos_empresas_muy_influyentes <- residuos[empresas_hatvalues_anomalos]
residuos_empresas_muy_influyentes
```

A simple vista no parece que tengamos un residuo muy grande. A pesar de estar aisladas, no parecen que tengan problemas con los residuos obtenidos por el modelo. De todas formas, podemos localizar estas empresas en un gráfico de residuos, en valor absoluto:

```{r}
# Muestro los residuos de todas las empresas
plot(
    hatco$empresa, abs(residuos),
    main = "Residuo estandarizado absoluto de cada una de las empresas",
    ylab = "Residuo",
    xlab = "Identificador de la empresa"
)

# Ahora localizo las dos empresas que estamos estudiando
# pch = 21 es para que el circulo salga rellenado y no vacio
points(
    empresas_hatvalues_anomalos, abs(residuos[empresas_hatvalues_anomalos]),
    col = "blue", pch = 19
)
```

Podemos observar que sus residuos son bajos en comparación al resto de empresas. Por tanto, no parece que sean datos problemáticos.

## Eliminación de observaciones anómalas e influyentes

En el estudio previo, hemos identificado las empresas 7 y 100 como empresas anómolas y muy influyentes. Por tanto, las vamos a eliminar de nuestro *dataset* y vamos a repetir el ajuste del modelo.

### Filtrado del *dataset*

```{r}

# Repito este calculo porque hemos usado la misma variable para detectar
# anomalias con 2.0 en vez de con 2.5
empresas_anomalas <- hatco[abs(residuos) > 2.5, ]$empresa

# Filtramos el dataset
hatcoclean <- hatco[hatco$empresa != empresas_anomalas, ]

# Miramos que solo tengamos 98 filas en el dataset limpiado
nrow(hatcoclean)
```

### Re-ajuste del modelo

Ahora que ya hemos realizado el filtrado, volvemos a ajustar el modelo:

```{r}
mod2 <- lm(fidelidad~velocidad+precio+flexprec+imgfabri+servconj+imgfvent+calidadp, hatcoclean)
mod2
```

### Estudio de la bondad del nuevo ajuste

Repetimos los cálculos sobre la bondad del ajuste y contrastes de signifiación individuales para el nuevo ajuste logrado.


Miramos la bondad del ajuste

```{r }
print(summary(mod2))
```

Notar que ahora tenemos un *adjusted* $R^2$ con un valor de $0.7975$. En la primer regresión obtuvimos un valor de $0.7578$ para esta métrica. Por tanto, parece que con este pequeño filtrado hemos mejorado notablemente los resultados de nuestro modelo.

Realizamos el test ANOVA

```{r }
anovares <- anova(mod2)
anovares
```

<!-- TODO -- todo lo que sigue es copiado de un apartado anterior. Hay que desarrollarlo para el nuevo modelo ->

Usamos summary para ver si las percepciones son relevantes en la variable de salida:
Viendo los p-valores que estan por debajo de 0.05, las unicas variables relevantes son (las que rechazan H0):

- Flexprec
- Servconj
- Y ademas el parametro independiente $\beta_0$

A un nivel de significación del 1%

- Intercept ($\beta_0$) se rechaza pues su p-valor es $0.044 > 0.01$
