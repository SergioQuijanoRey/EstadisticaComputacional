---
title: Sesión de prácticas 9, Estadística Computacional \n
subtitle: Informe estadístico y regresión lineal múltiple
author:
  - Sergio Quijano Rey
  - sergioquijano@correo.ugr.es
date: 12.05.2022
output:
    html_document:
        toc: true
        toc_depth: 3
        toc_float: false
        collapsed: true
        number_sections: true
---

# Notas previas

- Algunas salidas se muestran mal porque uso mucho `message` y `print`
- Antes usaba estas funciones para mostrar por la consola de *Linux* los resultados y distintas secciones de la práctica
- Para mejorar las salidas del programa, muchos `message()` se pueden sustituir por texto en *markdow* que muestre las mismas indicaciones que estaba mostrando con los mensajes en `R`.
- Hago este proceso a mano, para mejorar la legibilidad del *notebook*

# Carga de los datos

Hacemos `as.is = NA` para que todos los factores se identifiquen en el dataframe como tal

```{r }
hatco <- read.csv("hatco2.csv", header = TRUE, as.is = NA)
```

Las primeras 10 filas del *dataframe* son:

```{r}
head(hatco, 10)
```

La estructura del *dataframe* leído es:

```{r}
str(hatco)
```

Representamos graficamente las variables con las que vamos a estar trabajando Nos interesa ver las correlaciones entre las variables

```{r }
plot(hatco[,c(6:13)])
```

Podemos ver que la fidelidad (variable que queremos predecir en base a las otras) esta ligeramente correlada linealmente con:

- Velocidad
- Servconj
- Flexprec (ligeramente)

Algunas variables explicativas parecen ser algo colineales:

- Imgfvent y Imgfabri
- Servconj y velocidad
- Servconj y precio (muy ligeramente)

# Ajuste de un modelo lineal a los datos

Realizamos el ajuste lineal

```{r }
mod1 <- lm(fidelidad~velocidad+precio+flexprec+imgfabri+servconj+imgfvent+calidadp, hatco)
mod1
```

## Estudio de la bondad del ajuste

Miramos la bondad del ajuste

```{r }
print(summary(mod1))
```

De este `summary`, podemos ver que el valor ajustado de $R^2$ es de $0.7578$. Por tanto el ajuste lineal no es perfecto pero es suficientemente bueno como para seguir con el estudio.

Usamos `summary` para ver si las percepciones son relevantes en la variable de salida. Viendo los p-valores que estan por debajo de 0.05, las unicas variables relevantes son (las que rechazan H0):

- Flexprec
- Servconj
- Y ademas el parametro independiente $\beta_0$

A un nivel de significación del 1%

- Intercept ($\beta_0$) se rechaza pues su p-valor es $0.044 > 0.01$

Realizamos el test ANOVA

```{r }
anovares <- anova(mod1)
anovares
```

Vemos que las variables que sirven para explicar la varianza del conjunto de datos son:

- velocidad
- precio
- flexprec
- imgfabri
- En mucha menor medida, servconj

Las variables que más variabilidad explican (en orden descendente) son:

1. velocidad
2. flexprec
3. precio

Las siguientes variables explican muchísimo menos la variabilidad del conjunto de datos.

# Diagnóstico del modelo

## Estudiamos la homocedasticidad

```{r }
residuos <- rstandard(mod1)
predicciones <- mod1$fitted.values #' Las predicciones ya nos las da el objeto devuelto por lm
```
Gráfico de dispersión de los pares $\hat{y_i}, r_i$

```{r}
plot(predicciones, residuos)
```

Grafico de dispersion de los pares $x_{ij}, r_i$

```{r, fig.height=20, fig.width=15}
par(mfrow=c(4,2))
for(j in 6:13){
  plot(hatco[, j], residuos)
}
```

**Conclusiones**:

- Todos estos graficos muestran nubes de puntos aleatorias
- Ademas, la dispersion parece uniforme, salvo en valores de la variable x_i donde tenemos pocos puntos

## Estudiamos la incorrelacion

Empezamos realizando una comprobación gráfica de que los datos están incorrelados. Para ello, mostramos gráficamente los errores estandarizados (que anteriormente calculábamos con `rstandar`) frente a la variable `empresa`

```{r}
plot(hatco$empresa, residuos)
```

A partir de estas gráficas, podemos extraer las siguientes **conclusiones**:

- Parece que estamos visualizando un patrón aleatorio en la gráfica
- Por tanto, parece que no existen las correlaciones que podrían invalidar las hipótesis iniciales que hemos tomado como dadas y que ahora estamos comprobando

Ahora, usamos el *test* de *Durbin-Watson* para comprobar lo que hemos comentado previamente:

```{r}
library(lmtest)
dwtest(mod1)
```

En este test, la hipótesis nula $H_0$ es que las autocorrelaciones es cero. Por tanto, lo que buscamos es que el $p-value$ del test sea grande, por encima de $0.05, 0.1$ aproximadamente.

En nuestro caso, como tenemos un $p-value$ de $0.3179 >> 0.1$, no podemos rechazar $H_0$, y por tanto, podemos pensar que las autocorrelaciones son cero, que es lo que íbamos buscando.

## Estudiamos la normalidad de los errores

Los errores del modelo se asumen normales. Dicha hipótesis es fundamental para el desarrollo de la inferencia. Por tanto es esencial verificar esta hipótesis.

Para realizar dicha verificación vamos a usar el *test* *Kolmogorov-Smirnov*:

```{r}
# Tomamos la media y desviacion de los residuos, porque estos parametros son necesarios para la
# funcion ks.test. Si no pasamos estos parametros, se supone media cero y desviacion 1
# Notar que deberian ser media cero y desviacion uno porque son residuos estandarizados. Pero tomamos
# estos valores por si han ocurrido errores numericos, paliarlos un poco
residuos.mean <- mean(residuos)
residuos.sd <- sd(residuos)


# Especificamos "pnorm" porque es la cdf de la distribucion con la que queremos comprobar
ks.test(residuos, "pnorm", residuos.mean, residuos.sd)
```

Vemos que los residuos tienen media cero y desviación 1, porque como decimos en el comentario, estamos usando los residuos estandarizados:

```{r}
residuos.mean
residuos.sd
```

Se confirma lo que decíamos anteriormente.

Respecto a los resultados del *test*, extraemos las siguientes **conclusiones**:

- Tenemos que $p-value \geq 0.05$, luego no podemos rechazar la hipótesis nula
- Dicha hipótesis nula es que la distribución de los datos no sigue una normal estándar
- Por tanto, no tenemos evidencia para pensar que los residuos no sigan una normal estándar, así que podemos pensar que sí que la sigue

Ahora, para reforzar el resultado del test *Kolmogorov-Smirnov*, mostramos una visualización usando un **gráfico probabilístico normal** (también llamado gráfico *cuantil-cuantil*) usando `qqnorm`:

```{r}
qqnorm(residuos)

# Usamos qqline para mostrar la linea que deberia seguir los datos para que al distribucion
# siguiese realmente una distribucion normal
qqline(residuos)
```

Con este gráfico lo que buscamos es que los datos se muestren gráficamente aproximadamente como una línea recta. Por tanto:

- Los residuos se distribuyen de forma parecida a una normal, aunque no se ajusten a esta distribución perfectamente
- Esto, en conjunto con los resultados del *test de Kolmogorov-Smirnov*, podemos pensar que los residuos siguen una distribución normal estándar, como buscábamos


## Estudiamos la linealidad de los errores

Hemos supuesto previamente la linealidad en la relación entre la respuesta y las variables explicativas. Esto se puede comprobar en los gráficos de dispersión que hemos mostrado previamente. Pero para esta tarea son más adecuados los gráficos *componente más residuo*, que mostramos a continuación:

```{r}
# Esta libreria no viene instalada por defecto, asi que hay que instalarla
# antes de usarla antes de usarla
library(car)

# Cargada la libreria, mostramos la grafica componente mas residuos
crPlots(mod1)
```

En las siguientes variables, la **linealidad es clara**:

- Precio
- flexprec
- servconj

Pero en las siguientes variables, la **linealidad no es clara**, pero tampoco se desvía mucho de la relación lineal que vemos con las líneas discontinuas:

- Velocidad
- imgfabri
- imgfvent
- calidadp

Sí que es verdad que los errores en `velocidad` se desvían mucho más de una relación lineal, y parecen seguir una relación cuadrática. Sin embargo, la desviación no es lo suficientemente grande como para que nos preocupe.

## Identificación de datos anómalos

Como datos anómalos identificamos aquellos datos cuyos residuos sean excesivamente grandes. Para ello, consideraremos los residuos estandarizados o estudentizados, y detectaremos datos anómalos aquellos cuyos residuos estén por encima del rango $(-2, 2)$, y excesivamente anómalos aquellos que estén por encima del rango $(-3, 3)$.

A continuación, localizo las empresas con un residuo $|res_i| > 2.5$:

```{r}
# Selecciono aquellas filas que cumplen la condicion buscada
empresas_anomalas <- hatco[abs(residuos) > 2.5, ]$empresa
empresas_anomalas
```

Por tanto, vemos que tenemos dos empresas anómalas, la empresa con identificador 7 y la empresa con identificador 100. Repito lo anterior pero usando como umbral $2$ en vez de $2.5$:

```{r}
# Selecciono aquellas filas que cumplen la condicion buscada
empresas_anomalas <- hatco[abs(residuos) > 2, ]$empresa
empresas_anomalas
```

Con este criterio más suave (es más propenso a detectar anomalías), tenemos también las empresas 11 y 14 como empresas anómalas.

## Identificación de datos influyentes

Como datos influyentes identificamos aquellos que tienen un impacto desproporcionado sobre los resultados de la regresión. Si además se tratan de datos aislados, estos datos deberían ser tratados.

Para identificar estos datos, usaremos la **distancia de Cook** $D_i$ que calcularemos usando `cooks.distance`. Realizamos dicho estudio y mostramos las distancias gráficamente:

```{r}
distancias <- cooks.distance(mod1)
plot(
     hatco$empresa, distancias,
     main = "Distancia Cook de cada una de las empresas",
     ylab = "Distancia Cook",
     xlab = "Identificador de la empresa"
)
```

En esta gráfica vemos que hay datos cuya distancia *Cook* (recordemos que mide la influencia que han tenido los datos en la regresión) es mucho más grande que el resto de datos. Especialmente uno hacia la izquierda (entre el 0 y el 20) y el valor 100. Sabemos que el 100 tiene un residuo demasiado elevado. Veamos si localizamos el otro dato, que sospechamos que es el 7 (por el previo estudio de residuos):

```{r}
empresas_distancias_anomalas <- hatco[distancias > 0.05, ]$empresa
empresas_distancias_anomalas
```

Efectivamente, son las empresas que ya habíamos detectado como anómalas al estudiar sus residuos estandarizados. Por tanto, sabemos que estos datos que han sido demasiasdo influyentes en la regresión son datos anómalos. Esto puede ser negativo porque los valores anómalos pueden estar empeorando los resultados de la regresión.

Todo este trabajo se simplifica bastante con la librería `car`. Mostramos cómo se usa a continuación:

```{r}
library(car)
influenceIndexPlot(mod1)
```

Con esta librería, podemos visualizar los gráficos que hemos usado previamente para localizar datos anómalos en una sola imagen. Además, tenemos algunas gráficas adicionales que nos pueden ser útiles.


## Identificación de datos aislados

Para medir el aislamiento de estos datos usaremos los valores de la diagonal de la matriz *hat*: $\hat{H} = X (X X')^{-1} X'$ que se puede obtener con la función `hatvalues`.

Estudiamos dichos *hatvalues* y los mostramos gráficamente:

```{r}
hatvalues <- hatvalues(mod1)
plot(
    hatco$empresa, hatvalues,
    main = "hatvalues de cada una de las empresas",
    ylab = "hatvalue",
    xlab = "Identificador de la empresa"
)
```

Visualmente, identificamos dos empresas con *hatvalues* desproporcionados. Además, no se pueden tratar de las empresas 7 y 100. Veamos de qué empresas se tratan:

```{r}
empresas_hatvalues_anomalos <- hatco[hatvalues > 0.35, ]$empresa
empresas_hatvalues_anomalos
```

Tenemos por tanto dos empresas que podrían necesitar de un estudio independiente, la 22 y la 55, por estar demasiado aisladas.

Puedo mostrar gráficamente estas empresas que se han detectado como excesivamente aisladas:

```{r}
# Muestro graficamente estas empresas anomalas
plot(
    hatco$empresa, hatvalues,
    main = "hatvalues de cada una de las empresas",
    ylab = "hatvalue",
    xlab = "Identificador de la empresa"
)

# pch = 21 es para que el circulo salga rellenado y no vacio
points(empresas_hatvalues_anomalos, hatvalues[empresas_hatvalues_anomalos], col = "blue", pch = 19)
```

Veamos el residuo que tienen estos valores aislados:

```{r}
residuos_empresas_muy_influyentes <- residuos[empresas_hatvalues_anomalos]
residuos_empresas_muy_influyentes
```

A simple vista no parece que tengamos un residuo muy grande. A pesar de estar aisladas, no parecen que tengan problemas con los residuos obtenidos por el modelo. De todas formas, podemos localizar estas empresas en un gráfico de residuos, en valor absoluto:

```{r}
# Muestro los residuos de todas las empresas
plot(
    hatco$empresa, abs(residuos),
    main = "Residuo estandarizado absoluto de cada una de las empresas",
    ylab = "Residuo",
    xlab = "Identificador de la empresa"
)

# Ahora localizo las dos empresas que estamos estudiando
# pch = 21 es para que el circulo salga rellenado y no vacio
points(
    empresas_hatvalues_anomalos, abs(residuos[empresas_hatvalues_anomalos]),
    col = "blue", pch = 19
)
```

Podemos observar que sus residuos son bajos en comparación al resto de empresas. Por tanto, no parece que sean datos problemáticos.

## Eliminación de observaciones anómalas e influyentes

En el estudio previo, hemos identificado las empresas 7 y 100 como empresas anómolas y muy influyentes. Por tanto, las vamos a eliminar de nuestro *dataset* y vamos a repetir el ajuste del modelo.

### Filtrado del *dataset*

```{r}

# Repito este calculo porque hemos usado la misma variable para detectar
# anomalias con 2.0 en vez de con 2.5
empresas_anomalas <- hatco[abs(residuos) > 2.5, ]$empresa

# Filtramos el dataset
hatcoclean <- hatco[hatco$empresa != empresas_anomalas, ]

# Miramos que solo tengamos 98 filas en el dataset limpiado
nrow(hatcoclean)
```

### Re-ajuste del modelo

Ahora que ya hemos realizado el filtrado, volvemos a ajustar el modelo:

```{r}
mod2 <- lm(fidelidad~velocidad+precio+flexprec+imgfabri+servconj+imgfvent+calidadp, hatcoclean)
mod2
```

### Estudio de la bondad del nuevo ajuste

Repetimos los cálculos sobre la bondad del ajuste y contrastes de signifiación individuales para el nuevo ajuste logrado.


Miramos la bondad del ajuste

```{r }
print(summary(mod2))
```

Notar que ahora tenemos un *adjusted* $R^2$ con un valor de $0.7975$. En la primer regresión obtuvimos un valor de $0.7578$ para esta métrica. Por tanto, parece que con este pequeño filtrado hemos mejorado notablemente los resultados de nuestro modelo.

Veamos qué variables son relevantes para determinar la variable de salida. Viendo los p-valores que estan por debajo de 0.05, las unicas variables relevantes son (las que rechazan H0):

- `flexprec`
- `servconj`
- `imgfvent`
- Y ademas el parametro independiente $\beta_0$

Respecto al ajuste anterior, tenemos las mismas variables relevantes, a la que se suma `imgfvent`. Por tanto, al hacer la limpieza hacemos que la variable `imgfvent` gane relevancia en el ajuste.

Realizamos el test ANOVA

```{r }
anovares <- anova(mod2)
anovares
```

De esto, sacamos las siguientes **conclusiones**:

- Todas las variables, salvo `calidadp`, sirven de forma significativa para explicar la varianza del conjunto de datos
- Las variables que más varianza explican, ordenadas de mayor a menor varianza explicada, son:
    1. Velocidad
    2. `flexprec`
    3. `precio`
- Las siguientes variables explican en muchísima menor medida la varianza que las tres primeras variables que acabamos de comentar

> En lo que sigue, vamos a usar el nuevo modelo ajustado como modelo principal

## Estudio de la multicolinealidad

Con los contrastes de significación individual de cada percepción $x_j$, hemos visto que hay variables redundantes en el modelo. Es importante que confirmemos que esto supone un problema serio de multicolinealidad. Para descartar la existencia de multicolinealidad seguimos los siguientes pasos:

1. Calculamos la matriz de correlaciones $R$ entre percepciones dos a dos, buscando correlaciones muy elevadas que supondrían problemas
2. Calculamos el índice de condicionamiento de la matriz $R$, y comprobamos que esté por debajo de 30
3. Para cada una de las 7 percepciones, calculamos el factor de inflado de la varianza $VIF$. Todos deben estar por debajo de 10, y preferentemente, por debajo de 5

Comenzamos con la matriz de correlaciones:

```{r}
R <- cor(hatcoclean[, 6:12])
R
```

Visualizamos dicha matriz, para que el estudio sea más sencillo a simple vista. Para ello, es necesario tener instalado el paquete `corrplot:`

```{r}
library(corrplot)
corrplot(R)
```

Con esto, es fácil ver que:

- velocidad y servconj están bastante correlados (en concreto, $0.6065647$)
- velocidad y flexprec están algo correlados (en concreto, $0.51439674$)
- velocidad y calidadp están algo correlados (en concreto, $-0.4951789$)
- precio y flexprec están algo correlados (en concreto, $-0.48923614$)
- precio y serconj están algo correlados (en concreto, $0.5127076$)
- precio y calidadp están algo correladas (en concreto, $0.4684921$)
- ...

Como tenemos muchas correlaciones suaves, nos centramos ahora en las que están por encima de $0.6$ en valor absoluto:

- imgfabri e imgfvent están muy correladas (en concreto, $0.78999087$)
- velocidad y servconj están bastante correlados (en concreto, $0.6065647$)

Estas dos correlaciones tan altas pueden ser un problema. Para investigar más sobre la posible problemática, calculamos ahora el índice de condicionamiento de la matriz $R$:

```{r}
ai <- eigen(R)$values
cond_val <- sqrt(max(ai) / min(ai))
cond_val
```

Dicho índice está por debajo de 30, así que parece que las anteriores correlaciones no son demasiado peligrosas. Ahora calculamos el factor de inflado de la varianza:

```{r}
vif(mod2)
```

Buscamos que todos estén por debajo de 10, y preferiblemente, por debajo de 5. Sin embargo, `velocidad, precio, servconj` están por encima de 30 (de hecho, `serconj` por encima de 40), y por tanto, parece que tenemos un **problema de multicolinealidad con estas tres variables**.

# Selección de variables explicativas

En apartados anteriores, ya hemos visto que ciertas variables no son del todo útiles, y que ciertas variables pueden tener un problema de multicolinealidad. En esta sección vamos a usar un método de selección automática de variables explicativas paso a paso (*stepwise*).

Vamos a aplicar un algoritmo de este tipo basado en el **criterio de Akaike** (*AIC*). El algoritmo añade y elimina variables basándose en el *AIC*. Devuelve el modelo que menor valor de *AIC* ha logrado. Lo aplicamos al segundo modelo construido:

```{r}
step(mod2)
```

El modelo ha empezado con las 7 variables, y ha acabado con las variables:

- `flexprec`
- `servconj`
- `imgfvent`
- `calidadp`

Por tanto, `direction = 'backward'`. Probamos ahora en dos direcciones:

```{r}
step(mod2, direction = "both")
```

Acabamos con el mismo modelo que con `'backward'`. El valor de *AIC* logrado es el mismo que en caso anterior. Por lo tanto, nos podemos quedar con dicho modelo y ver qué resultados nos ofrece:

```{r}
mod3 <- step(mod2, direction = "both")
```

## Estudio de la calidad del nuevo modelo obtenido

Miramos la bondad del ajuste

```{r }
print(summary(mod3))
```

Hemos logrado un $R^2$ ajustado de 0.8013, que supone cierto margen de mejora respecto al $R^2$ del segundo modelo de $0.7975$

Vemos que todas las variables, salvo `calidadp`, son relevantes. Quizás esto se deba a que, al habernos quedado con las mejores variables, `calidadp` no destaca demasiado a pesar de ser una buena variable. De hecho, ya hemos comentado esto previamente, las tres mejores variables destacan demasiado sobre las siguientes variables.

Realizamos ahora el test ANOVA

```{r }
anovares <- anova(mod3)
anovares
```

Pasa lo mismo con la variable `calidadp`, y los motivo pueden ser los mismos.

## Eliminación de la variable `calidadp`

Estoy viendo que `calidadp` puede no ser una buena variable, aunque haya sido escogida en el algoritmo *stepwise*. Así que elimino esta variable manualmente y miro la calidad del ajuste realizado. Empiezo realizando la regresión sin esta variable:

```{r}
mod4 <- lm(formula = fidelidad ~ flexprec + servconj + imgfvent,  data = hatcoclean)
```

Ahora, veamos la calidad del ajuste realizado:

```{r}
summary(mod4)
```

El valor de $R^2$ ha bajado respecto al modelo obtenido con el algoritmo *stepwise*. Por tanto, podemos pensar que la variable `calidadp` es útil a la hora de realizar el ajuste lineal de los datos.

